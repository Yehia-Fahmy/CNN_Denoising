{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0fp4xr40ezm"
      },
      "source": [
        "## Autoencoder\n",
        "\n",
        "An autoencoder is an unsupervised learning technique for neural networks that learns efficient data representations (encoding) by training the network to ignore signal “noise.” Autoencoders can be used for image denoising, image compression, and, in some cases, even generation of image data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9lekBx91fNW"
      },
      "source": [
        "## Flow of Autoencoder\n",
        "\n",
        "Noisy Image -> Encoder -> Compressed Representation -> Decoder -> Reconstruct Clear Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9KVxNq313dP"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8dcyQ4LdzZ67"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import Sequential, Model\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, ReLU, Add, Input\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Enable GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "        print(\"Using GPU:\", gpus[0])\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrk-gzKi3Bao"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import kagglehub\n",
        "\n",
        "# Download the latest version of the CelebA dataset\n",
        "# path = kagglehub.dataset_download(\"jessicali9530/celeba-dataset\")\n",
        "# print(\"Path to dataset files:\", path)\n",
        "path = \"/Users/yfahmy/.cache/kagglehub/datasets/jessicali9530/celeba-dataset/versions/2/img_align_celeba/\"\n",
        "\n",
        "# Path to the directory where the CelebA images are stored\n",
        "base_dir = os.path.join(path, \"img_align_celeba\")  # Adjust if needed\n",
        "\n",
        "# Image size to resize all images to\n",
        "image_dim = 200\n",
        "num_channels = 3\n",
        "\n",
        "# Initialize a list to hold image data\n",
        "images = []\n",
        "\n",
        "# Optional: limit number of images if needed\n",
        "MAX_IMAGES = 10000\n",
        "\n",
        "# Loop through images in the dataset directory\n",
        "for i, filename in enumerate(os.listdir(base_dir)):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(base_dir, filename)\n",
        "\n",
        "        try:\n",
        "            if num_channels == 3:\n",
        "                img = Image.open(image_path).convert(\"RGB\")\n",
        "            else:\n",
        "                img = Image.open(image_path).convert(\"L\")\n",
        "            img = img.resize((image_dim, image_dim))\n",
        "            images.append(np.array(img))\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {image_path}: {e}\")\n",
        "\n",
        "        if i + 1 >= MAX_IMAGES:\n",
        "            break\n",
        "\n",
        "# Convert list to numpy array\n",
        "images = np.array(images)\n",
        "\n",
        "# Split into training and testing sets\n",
        "x_train, x_test = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Ensure the correct shape for TensorFlow (batch, height, width, channels)\n",
        "x_train = x_train.reshape(len(x_train), image_dim, image_dim, num_channels)\n",
        "x_test = x_test.reshape(len(x_test), image_dim, image_dim, num_channels)\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape}, x_test shape: {x_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index = np.random.randint(len(x_train))\n",
        "image = x_train[index]\n",
        "\n",
        "def calculate_2dft(input):\n",
        "    ft = np.fft.ifftshift(input)\n",
        "    ft = np.fft.fft2(ft)\n",
        "    return np.fft.fftshift(ft)\n",
        "\n",
        "def calculate_2dift(input):\n",
        "    ift = np.fft.ifftshift(input)\n",
        "    ift = np.fft.ifft2(ift)\n",
        "    ift = np.fft.fftshift(ift)\n",
        "    return ift.real\n",
        "\n",
        "def calculate_distance_from_centre(coords, centre):\n",
        "    # Distance from centre is √(x^2 + y^2)\n",
        "    return np.sqrt(\n",
        "        (coords[0] - centre) ** 2 + (coords[1] - centre) ** 2\n",
        "    )\n",
        "\n",
        "def find_symmetric_coordinates(coords, centre):\n",
        "    return (centre + (centre - coords[0]),\n",
        "            centre + (centre - coords[1]))\n",
        "\n",
        "def display_plots(individual_grating, reconstruction, idx):\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(individual_grating)\n",
        "    plt.axis(\"off\")\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(reconstruction)\n",
        "    plt.axis(\"off\")\n",
        "    plt.suptitle(f\"Terms: {idx}\")\n",
        "    plt.pause(0.01)\n",
        "\n",
        "# # Read and process image\n",
        "# image = image[:, :, :3].mean(axis=2)  # Convert to grayscale\n",
        "\n",
        "def foureir_transform(image, display=False):\n",
        "    plt.set_cmap(\"gray\")\n",
        "\n",
        "    ft = calculate_2dft(image)\n",
        "\n",
        "    if display:\n",
        "        # Show grayscale image and its Fourier transform\n",
        "        plt.subplot(121)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplot(122)\n",
        "        plt.imshow(np.log(abs(ft)))\n",
        "        plt.axis(\"off\")\n",
        "        plt.pause(2)\n",
        "        fig = plt.figure()\n",
        "\n",
        "    return ft\n",
        "\n",
        "\n",
        "def inverse_fourier_transform(ft, display=False):\n",
        "    # Reconstruct image\n",
        "\n",
        "    # Step 1\n",
        "    # Set up empty arrays for final image and\n",
        "    # individual gratings\n",
        "    rec_image = np.zeros(image.shape)\n",
        "    individual_grating = np.zeros(\n",
        "        image.shape, dtype=\"complex\"\n",
        "    )\n",
        "    idx = 0\n",
        "\n",
        "    # All steps are displayed until display_all_until value\n",
        "    display_all_until = 200\n",
        "    # After this, skip which steps to display using the\n",
        "    # display_step value\n",
        "    display_step = 50\n",
        "    # Work out index of next step to display\n",
        "    next_display = display_all_until + display_step\n",
        "\n",
        "    # Step 2\n",
        "    for coords in coords_left_half:\n",
        "        # Central column: only include if points in top half of\n",
        "        # the central column\n",
        "        if not (coords[1] == centre and coords[0] > centre):\n",
        "            idx += 1\n",
        "            symm_coords = find_symmetric_coordinates(\n",
        "                coords, centre\n",
        "            )\n",
        "            # Step 3\n",
        "            # Copy values from Fourier transform into\n",
        "            # individual_grating for the pair of points in\n",
        "            # current iteration\n",
        "            individual_grating[coords] = ft[coords]\n",
        "            individual_grating[symm_coords] = ft[symm_coords]\n",
        "\n",
        "            # Step 4\n",
        "            # Calculate inverse Fourier transform to give the\n",
        "            # reconstructed grating. Add this reconstructed\n",
        "            # grating to the reconstructed image\n",
        "            rec_grating = calculate_2dift(individual_grating)\n",
        "            rec_image += rec_grating\n",
        "\n",
        "            # Clear individual_grating array, ready for\n",
        "            # next iteration\n",
        "            individual_grating[coords] = 0\n",
        "            individual_grating[symm_coords] = 0\n",
        "\n",
        "            # Don't display every step\n",
        "            if idx < display_all_until or idx == next_display:\n",
        "                if idx > display_all_until:\n",
        "                    next_display += display_step\n",
        "                    # Accelerate animation the further the\n",
        "                    # iteration runs by increasing\n",
        "                    # display_step\n",
        "                    display_step += 10\n",
        "    if display:\n",
        "        display_plots(rec_grating, rec_image, idx)\n",
        "        plt.show()\n",
        "    return rec_image\n",
        "\n",
        "# Array dimensions (array is square) and centre pixel\n",
        "array_size = len(image)\n",
        "centre = int((array_size - 1) / 2)\n",
        "\n",
        "# Get all coordinate pairs in the left half of the array,\n",
        "# including the column at the centre of the array (which\n",
        "# includes the centre pixel)\n",
        "coords_left_half = (\n",
        "    (x, y) for x in range(array_size) for y in range(centre+1)\n",
        ")\n",
        "print(coords_left_half)\n",
        "\n",
        "# Sort points based on distance from centre\n",
        "coords_left_half = sorted(\n",
        "    coords_left_half,\n",
        "    key=lambda x: calculate_distance_from_centre(x, centre)\n",
        "    )\n",
        "\n",
        "ft = foureir_transform(image, display=True)\n",
        "# plt.subplot(121)\n",
        "# plt.imshow(np.log(abs(ft)))\n",
        "# plt.axis(\"off\")\n",
        "# plt.subplot(122)\n",
        "# plt.imshow(np.log(abs(ft)))\n",
        "# plt.axis(\"off\")\n",
        "# plt.pause(2)\n",
        "# fig = plt.figure()\n",
        "rec_image = inverse_fourier_transform(ft, display=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJSXWAAfq2yH"
      },
      "source": [
        "## Add Gaussian Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6KoKR6MMq597"
      },
      "outputs": [],
      "source": [
        "noise_factor = 0.075\n",
        "# Gaussian Noise\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index = np.random.randint(len(x_train_noisy))\n",
        "image = x_train_noisy[index]\n",
        "ft = foureir_transform(image)\n",
        "plt.subplot(121)\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.log(abs(ft)))\n",
        "plt.axis(\"off\")\n",
        "plt.pause(2)\n",
        "fig = plt.figure()\n",
        "rec_image = inverse_fourier_transform(ft)\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.log(abs(ft)))\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(122)\n",
        "plt.imshow(rec_image)\n",
        "plt.axis(\"off\")\n",
        "plt.pause(2)\n",
        "fig = plt.figure()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add Salt and Pepper Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def add_s_and_p_noise_batch(images, salt_prob=0.01, pepper_prob=0.01):\n",
        "#     N, H, W, C = images.shape\n",
        "#     rand_matrix = np.random.rand(N, H, W)\n",
        "#     salt_mask = rand_matrix < salt_prob\n",
        "#     pepper_mask = rand_matrix > (1 - pepper_prob)\n",
        "#     images[salt_mask] = 255\n",
        "#     images[pepper_mask] = 0\n",
        "#     return images\n",
        "\n",
        "# x_train_noisy = add_s_and_p_noise_batch(x_train_noisy)\n",
        "# x_test_noisy = add_s_and_p_noise_batch(x_test_noisy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate Fourier Transform of the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_noisy_fourier = np.array([foureir_transform(image) for image in x_train_noisy])\n",
        "x_train_fourier = np.array([foureir_transform(image) for image in x_train])\n",
        "x_test_noisy_fourier = np.array([foureir_transform(image) for image in x_test_noisy])\n",
        "x_test_fourier = np.array([foureir_transform(image) for image in x_test])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_complex_channels(data):\n",
        "    print(f\"original shape: {data.shape}\")\n",
        "    \"\"\"\n",
        "    Converts (N, H, W, 3) complex64 array to (N, H, W, 6) real-valued array\n",
        "    by separating real and imaginary parts of each channel.\n",
        "    \n",
        "    Parameters:\n",
        "        data (np.ndarray): Complex-valued input of shape (N, H, W, 3)\n",
        "    \n",
        "    Returns:\n",
        "        np.ndarray: Real-valued output of shape (N, H, W, 6)\n",
        "    \"\"\"\n",
        "    res = np.concatenate([\n",
        "        data.real,  # shape: (N, H, W, 3)\n",
        "        data.imag   # shape: (N, H, W, 3)\n",
        "    ], axis=-1)    # final shape: (N, H, W, 6)\n",
        "    print(f\"result shape: {res.shape}\")\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def combine_complex_channels(data):\n",
        "    print(f\"original shape: {data.shape}\")\n",
        "    \"\"\"\n",
        "    Converts (N, H, W, 6) real-valued array back to (N, H, W, 3) complex64 array\n",
        "    by recombining real and imaginary parts for each of the 3 channels.\n",
        "    \n",
        "    Parameters:\n",
        "        data (np.ndarray): Real-valued input of shape (N, H, W, 6)\n",
        "    \n",
        "    Returns:\n",
        "        np.ndarray: Complex-valued output of shape (N, H, W, 3)\n",
        "    \"\"\"\n",
        "    assert data.shape[-1] == 6, \"Input must have 6 channels (3 real + 3 imag)\"\n",
        "    \n",
        "    real = data[..., :3]  # First 3 channels: real\n",
        "    imag = data[..., 3:]  # Last 3 channels: imag\n",
        "    res = real + 1j * imag  # Shape: (N, H, W, 3), dtype=complex64\n",
        "    print(f\"result shape: {res.shape}\")\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_noisy_split = split_complex_channels(x_train_noisy_fourier)\n",
        "x_train_split = split_complex_channels(x_train_fourier)\n",
        "x_test_noisy_split = split_complex_channels(x_test_noisy_fourier)\n",
        "x_test_split = split_complex_channels(x_test_fourier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "itAs94xBq541"
      },
      "outputs": [],
      "source": [
        "# # clip the values in the range of 0-1\n",
        "# x_train_noisy_fourier = np.clip(x_train_noisy_fourier, 0., 1.)\n",
        "# x_test_noisy_fourier= np.clip(x_test_noisy_fourier, 0., 1.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UuBLkW25p3-"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JOiKQEwy5sKJ",
        "outputId": "c1ac5560-708e-461e-963a-d1654460f171"
      },
      "outputs": [],
      "source": [
        "index = np.random.randint(len(x_test_fourier))\n",
        "image = x_test[index]\n",
        "ft = x_test_noisy_fourier[index]\n",
        "plt.subplot(121)\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.log(abs(ft)))\n",
        "plt.axis(\"off\")\n",
        "plt.pause(2)\n",
        "fig = plt.figure()\n",
        "rec_image = inverse_fourier_transform(ft)\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.log(abs(ft)))\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(122)\n",
        "plt.imshow(rec_image)\n",
        "plt.axis(\"off\")\n",
        "plt.pause(2)\n",
        "fig = plt.figure()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(x_train_noisy_fourier.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KGiURME3-qH"
      },
      "source": [
        "## Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4XiApan38tv",
        "outputId": "9ca2f68d-b55c-4d84-a8b6-d68e2df11b7f"
      },
      "outputs": [],
      "source": [
        "# Regular network\n",
        "input_img = Input(shape=(image_dim, image_dim, num_channels * 2))  # to deal with complex numbers we need num of channels * 2\n",
        "\n",
        "# First layer (Conv + ReLU)\n",
        "x = Conv2D(64, (3, 3), padding='same')(input_img)\n",
        "x = ReLU()(x)\n",
        "\n",
        "for _ in range(6): \n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "# Last layer (Conv, No Activation)\n",
        "x = Conv2D(num_channels * 2, (3, 3), padding='same')(x) # to deal with complex numbers we need num of channels * 2\n",
        "\n",
        "# Skip Connection (Residual Learning)\n",
        "output_img = Add()([input_img, x])\n",
        "\n",
        "model = Model(inputs=input_img, outputs=output_img)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNlBUXuX5YCo",
        "outputId": "e322b4db-d9bd-4165-b1c7-756efa3bf3a2"
      },
      "outputs": [],
      "source": [
        "# train the model\n",
        "model.fit(x_train_noisy_split, x_train_split, epochs=100 , batch_size=64, shuffle=True, validation_data=(x_test_noisy_split, x_test_split))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz1_i-Qx696G"
      },
      "source": [
        "## Visualize the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-abSf-97r-e"
      },
      "outputs": [],
      "source": [
        "# predict the results from model (get compressed images)\n",
        "predictions_split = model.predict(x_test_noisy_split)\n",
        "predictions_fourier = combine_complex_channels(predictions_split)\n",
        "predictions = np.array([inverse_fourier_transform(image) for image in predictions_fourier])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "I4MX_ELk77nf",
        "outputId": "7a8863ae-89c1-4648-feca-6878e0e94502"
      },
      "outputs": [],
      "source": [
        "index = np.random.randint(len(x_test))\n",
        "plt.figure(figsize=(20, 10))\n",
        "# display original image\n",
        "ax = plt.subplot(1, 3, 1)\n",
        "plt.imshow(x_test[index].reshape(image_dim,image_dim,1))\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "ax.set_title(\"Clean\")\n",
        "# display noisy image\n",
        "ax = plt.subplot(1, 3, 2)\n",
        "plt.imshow(x_test_noisy[index].reshape(image_dim,image_dim,1))\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "ax.set_title(\"Noisy\")\n",
        "# display cleaned image\n",
        "ax = plt.subplot(1, 3, 3)\n",
        "plt.imshow(inverse_fourier_transform(predictions[index].reshape(image_dim,image_dim,1)))\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "ax.set_title(\"Filtered\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Deep CNN Autoencoder - Denoising Image.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
